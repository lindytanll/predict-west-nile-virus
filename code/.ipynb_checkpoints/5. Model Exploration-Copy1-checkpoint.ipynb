{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17eb5c7b",
   "metadata": {},
   "source": [
    "# Project 4: Predict West Nile Virus\n",
    "### Section 5. Model Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70e632a",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "1. As an employee of Disease And Treatment Agency, division of Societal Cures In Epidemiology and New Creative Engineering (DATA-SCIENCE), we are tasked to better understand the mosquito population and advise on appropriate interventions which are beneficial and cost-effective for the city.\n",
    "\n",
    "\n",
    "2. Through this project, we hope to:\n",
    "- Identify features which are most important to predict presence of West Nile Virus (which can be done by ranking the coefficients of each feature in a logistic regression model)\n",
    "- Predict the probability of West Nile Virus by location to provide decision makers an effective plan to deploy pesticides throughout the city, which consequently can help to reduce cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae082b06",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7909f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install shapely\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# from shapely import geometry\n",
    "# from shapely.geometry import Point, Polygon\n",
    "# import geopandas as gpd\n",
    "# from datetime import timedelta\n",
    "# import math\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (confusion_matrix, plot_confusion_matrix, classification_report, \n",
    "                             plot_roc_curve, roc_auc_score, accuracy_score, precision_score, \n",
    "                             recall_score, f1_score)\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c25ebe",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4ab149da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df = pd.read_csv('../data/final_df.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d7b3c",
   "metadata": {},
   "source": [
    "### Split into train and test (Kaggle) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4903760a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8304, 240)\n",
      "(43035, 240)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test (kaggle) data \n",
    "train = df[df['dataset']=='train'].copy()\n",
    "test = df[df['dataset']=='test'].copy()\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6d36cf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns='dataset', inplace=True)\n",
    "test.drop(columns='dataset', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "81c44181",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>tavg</th>\n",
       "      <th>preciptotal</th>\n",
       "      <th>stnpressure</th>\n",
       "      <th>resultdir</th>\n",
       "      <th>avgspeed</th>\n",
       "      <th>is_spray</th>\n",
       "      <th>stnpressure_7</th>\n",
       "      <th>stnpressure_10</th>\n",
       "      <th>...</th>\n",
       "      <th>codesum_TSRA BR HZ VCTS</th>\n",
       "      <th>codesum_TSRA FG+ BR HZ</th>\n",
       "      <th>codesum_TSRA RA</th>\n",
       "      <th>codesum_TSRA RA BR</th>\n",
       "      <th>codesum_TSRA RA BR HZ</th>\n",
       "      <th>codesum_TSRA RA BR HZ VCTS</th>\n",
       "      <th>codesum_TSRA RA BR VCTS</th>\n",
       "      <th>codesum_TSRA RA VCTS</th>\n",
       "      <th>codesum_VCTS</th>\n",
       "      <th>wnvpresent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8304.000000</td>\n",
       "      <td>8304.000000</td>\n",
       "      <td>8304.000000</td>\n",
       "      <td>8304.000000</td>\n",
       "      <td>8304.000000</td>\n",
       "      <td>8304.000000</td>\n",
       "      <td>8304.000000</td>\n",
       "      <td>8304.000000</td>\n",
       "      <td>8304.000000</td>\n",
       "      <td>8304.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8304.000000</td>\n",
       "      <td>8304.0</td>\n",
       "      <td>8304.000000</td>\n",
       "      <td>8304.000000</td>\n",
       "      <td>8304.0</td>\n",
       "      <td>8304.0</td>\n",
       "      <td>8304.000000</td>\n",
       "      <td>8304.0</td>\n",
       "      <td>8304.000000</td>\n",
       "      <td>8304.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.845800</td>\n",
       "      <td>-87.696229</td>\n",
       "      <td>72.093931</td>\n",
       "      <td>0.182431</td>\n",
       "      <td>29.262110</td>\n",
       "      <td>17.842245</td>\n",
       "      <td>7.476903</td>\n",
       "      <td>0.008911</td>\n",
       "      <td>29.267480</td>\n",
       "      <td>29.251286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029383</td>\n",
       "      <td>0.037211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.055034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.106658</td>\n",
       "      <td>0.084440</td>\n",
       "      <td>7.630330</td>\n",
       "      <td>0.470450</td>\n",
       "      <td>0.118606</td>\n",
       "      <td>9.433945</td>\n",
       "      <td>2.543438</td>\n",
       "      <td>0.093984</td>\n",
       "      <td>0.131598</td>\n",
       "      <td>0.131994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168889</td>\n",
       "      <td>0.189290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062918</td>\n",
       "      <td>0.228060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>41.644612</td>\n",
       "      <td>-87.930995</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.890000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.890000</td>\n",
       "      <td>28.920000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41.750498</td>\n",
       "      <td>-87.752411</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.180000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.180000</td>\n",
       "      <td>29.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>41.862292</td>\n",
       "      <td>-87.696269</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.260000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.280000</td>\n",
       "      <td>29.260000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>41.947227</td>\n",
       "      <td>-87.648064</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>29.340000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.340000</td>\n",
       "      <td>29.340000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42.017430</td>\n",
       "      <td>-87.531635</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>3.970000</td>\n",
       "      <td>29.650000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.700000</td>\n",
       "      <td>29.670000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          latitude    longitude         tavg  preciptotal  stnpressure  \\\n",
       "count  8304.000000  8304.000000  8304.000000  8304.000000  8304.000000   \n",
       "mean     41.845800   -87.696229    72.093931     0.182431    29.262110   \n",
       "std       0.106658     0.084440     7.630330     0.470450     0.118606   \n",
       "min      41.644612   -87.930995    50.000000     0.000000    28.890000   \n",
       "25%      41.750498   -87.752411    69.000000     0.000000    29.180000   \n",
       "50%      41.862292   -87.696269    73.000000     0.000000    29.260000   \n",
       "75%      41.947227   -87.648064    78.000000     0.160000    29.340000   \n",
       "max      42.017430   -87.531635    87.000000     3.970000    29.650000   \n",
       "\n",
       "         resultdir     avgspeed     is_spray  stnpressure_7  stnpressure_10  \\\n",
       "count  8304.000000  8304.000000  8304.000000    8304.000000     8304.000000   \n",
       "mean     17.842245     7.476903     0.008911      29.267480       29.251286   \n",
       "std       9.433945     2.543438     0.093984       0.131598        0.131994   \n",
       "min       1.000000     2.100000     0.000000      28.890000       28.920000   \n",
       "25%       8.000000     5.800000     0.000000      29.180000       29.160000   \n",
       "50%      19.000000     7.100000     0.000000      29.280000       29.260000   \n",
       "75%      25.000000     9.400000     0.000000      29.340000       29.340000   \n",
       "max      36.000000    16.300000     1.000000      29.700000       29.670000   \n",
       "\n",
       "       ...  codesum_TSRA BR HZ VCTS  codesum_TSRA FG+ BR HZ  codesum_TSRA RA  \\\n",
       "count  ...              8304.000000                  8304.0      8304.000000   \n",
       "mean   ...                 0.006142                     0.0         0.029383   \n",
       "std    ...                 0.078132                     0.0         0.168889   \n",
       "min    ...                 0.000000                     0.0         0.000000   \n",
       "25%    ...                 0.000000                     0.0         0.000000   \n",
       "50%    ...                 0.000000                     0.0         0.000000   \n",
       "75%    ...                 0.000000                     0.0         0.000000   \n",
       "max    ...                 1.000000                     0.0         1.000000   \n",
       "\n",
       "       codesum_TSRA RA BR  codesum_TSRA RA BR HZ  codesum_TSRA RA BR HZ VCTS  \\\n",
       "count         8304.000000                 8304.0                      8304.0   \n",
       "mean             0.037211                    0.0                         0.0   \n",
       "std              0.189290                    0.0                         0.0   \n",
       "min              0.000000                    0.0                         0.0   \n",
       "25%              0.000000                    0.0                         0.0   \n",
       "50%              0.000000                    0.0                         0.0   \n",
       "75%              0.000000                    0.0                         0.0   \n",
       "max              1.000000                    0.0                         0.0   \n",
       "\n",
       "       codesum_TSRA RA BR VCTS  codesum_TSRA RA VCTS  codesum_VCTS  \\\n",
       "count              8304.000000                8304.0   8304.000000   \n",
       "mean                  0.010597                   0.0      0.003974   \n",
       "std                   0.102402                   0.0      0.062918   \n",
       "min                   0.000000                   0.0      0.000000   \n",
       "25%                   0.000000                   0.0      0.000000   \n",
       "50%                   0.000000                   0.0      0.000000   \n",
       "75%                   0.000000                   0.0      0.000000   \n",
       "max                   1.000000                   0.0      1.000000   \n",
       "\n",
       "        wnvpresent  \n",
       "count  8304.000000  \n",
       "mean      0.055034  \n",
       "std       0.228060  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 239 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2b99df22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8304 entries, 0 to 8303\n",
      "Columns: 239 entries, latitude to wnvpresent\n",
      "dtypes: float64(11), int64(228)\n",
      "memory usage: 15.2 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fffede",
   "metadata": {},
   "source": [
    "### Further Split Train Data into Train and Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0b20422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train data into X (all features except wnvpresent) and y (wnvpresent)\n",
    "features = [col for col in train.columns if col != 'wnvpresent']\n",
    "X = train[features]\n",
    "y = train['wnvpresent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f840f66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns[X.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "622dcd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.944966\n",
       "1.0    0.055034\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043d9808",
   "metadata": {},
   "source": [
    "- wnvpresent is highly inbalance, with only about 5.5% of the data points having West Nile Virus. \n",
    "    - It is important to stratify proportionally to ensure that our train and holdout dataset have about the same proportion of presence and absence of West Nile Virus.\n",
    "    - We also need to use SMOTE as the accuracy of our models without SMOTE is about 95% (i.e. close to the proportion of absence of WNV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ee5a32c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further split train data into train and holdout data\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(\n",
    "    X, \n",
    "    y,\n",
    "    stratify = y,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d0c0f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale our data\n",
    "ss = StandardScaler()\n",
    "Xs_train = ss.fit_transform(X_train)\n",
    "Xs_holdout = ss.transform(X_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac232dc",
   "metadata": {},
   "source": [
    "## Create synthetic data with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1fbf9ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create synthetic data for train set\n",
    "sm = SMOTE()\n",
    "Xsm_train, ysm_train = sm.fit_resample(Xs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "4217117a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11770, 238)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xsm_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4308775f",
   "metadata": {},
   "source": [
    "## Model Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc1a875",
   "metadata": {},
   "source": [
    "### Metrics to Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "74cd3281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacting a summary dataframe.\n",
    "summary_df = pd.DataFrame(columns=[\n",
    "    'transformer_estimator', \n",
    "    'best_score', \n",
    "    'train_score',\n",
    "    'holdout_score',\n",
    "    'sensitivity',\n",
    "    'specificity',\n",
    "    'f1_score',\n",
    "    'best_params', \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "07b1fed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transformer_estimator</th>\n",
       "      <th>best_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>holdout_score</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [transformer_estimator, best_score, train_score, holdout_score, sensitivity, specificity, f1_score, best_params]\n",
       "Index: []"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "39977633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_metrics(gs, X_train, y_train, X_test, y_test, modelname):\n",
    "    '''Generates confusion matrix and adds scores to summary_df'''\n",
    "    \n",
    "    #Generate confusion matrix\n",
    "    y_pred = gs.predict(X_test)\n",
    "    confusion_matrix(y_test, # True values.\n",
    "                     y_pred)  # Predicted values.\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel();\n",
    "\n",
    "    # Adding the scores into summary_df\n",
    "    \n",
    "    summary_df.loc[1] = [\n",
    "        modelname,\n",
    "        #'CountVec/LogisticRegression',\n",
    "        round(gs.best_score_, 3),\n",
    "        round(metrics.accuracy_score(X_train, y_train),3),\n",
    "        round(metrics.accuracy_score(X_test, y_test),3),\n",
    "        round(metrics.recall_score(y_test, y_pred),3),\n",
    "        round(tn/(tn+fp),3),\n",
    "        round(metrics.f1_score(y_test, y_pred),3),\n",
    "        str(gs.best_params_),\n",
    "    ]\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    plot_confusion_matrix(gs, X_test, y_test, cmap='Blues', \n",
    "                          display_labels=['WNV Present', 'WNV Not Present'],\n",
    "                          normalize='true');  \n",
    "    plt.title(label=modelname, fontsize=14)\n",
    "    plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "384a01fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_metrics(gs, X_train, y_train, X_test, y_test, modelname):\n",
    "    '''Generates confusion matrix and adds scores to summary_df'''\n",
    "    \n",
    "    #Generate confusion matrix\n",
    "    y_pred = gs.predict(X_test)\n",
    "    confusion_matrix(y_test, # True values.\n",
    "                     y_pred)  # Predicted values.\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel();\n",
    "\n",
    "    # Adding the scores into summary_df\n",
    "    \n",
    "    summary_df.loc[1] = [\n",
    "        modelname,\n",
    "        #'CountVec/LogisticRegression',\n",
    "        round(gs.best_score_, 3),\n",
    "        round(gs.score(X_train, y_train),3),\n",
    "        round(gs.score(X_test, y_test),3),\n",
    "        round(metrics.accuracy_score(y_test, y_pred),3),\n",
    "        round(metrics.recall_score(y_test, y_pred),3),\n",
    "        round(tn/(tn+fp),3),\n",
    "        round(metrics.f1_score(y_test, y_pred),3),\n",
    "        str(gs.best_params_),\n",
    "    ]\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    plot_confusion_matrix(gs, X_test, y_test, cmap='Blues', \n",
    "                          display_labels=['WNV Present', 'WNV Not Present'],\n",
    "                          normalize='true');  \n",
    "    plt.title(label=modelname, fontsize=14)\n",
    "    plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc02dc0",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "23641bab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Intercept: [-5.16162757]\n",
      "Logistic Regression Coefficient: [[-0.26251829 -0.29445554  0.08189278 -0.1696595  -0.2533853   0.17293977\n",
      "  -0.16101811  0.01879259 -0.27393549 -0.32610007 -0.07058427 -0.13103143\n",
      "   0.13098086 -0.02523724  0.08233639  0.04288399  0.         -0.00937357\n",
      "   0.11636009 -0.00937357 -0.0039041  -0.1101516   0.         -0.39833546\n",
      "   0.         -0.44345505  0.          0.8426758   0.         -0.53144752\n",
      "  -0.62166799 -0.56350981 -0.57984856 -0.26680902 -0.36173501 -0.47636697\n",
      "   0.17619121  0.53136629  0.73313451  0.60447533  0.47917561  0.51592157\n",
      "   0.39177895  0.49854824  0.50166235 -0.08046655  0.30459889 -0.12844957\n",
      "   0.04274683  0.05925667 -0.64737893  0.08261418 -0.04193556 -0.45613683\n",
      "   0.27540029  0.          0.          0.29462177 -0.13594262 -0.1682529\n",
      "   0.08087862 -0.20847651  0.22355832  0.10199126  0.02368548  0.18838535\n",
      "   0.07352845  0.2144631   0.10659596  0.06545884  0.14840668 -0.36060849\n",
      "  -0.2834188  -0.20439756 -0.23105486  0.11533491  0.26081452  0.11086986\n",
      "   0.04270707  0.08965713 -0.18028895 -0.22136936  0.02197011  0.023354\n",
      "  -0.20822044  0.09390916 -0.00369331 -0.32954382 -0.15181536  0.13358874\n",
      "  -0.37418659  0.0496211   0.12013801 -0.00877393 -0.18114951 -0.17580879\n",
      "   0.18298301  0.03579105 -0.14945394  0.11769822 -0.01099932  0.01683734\n",
      "   0.04930423  0.          0.11945033  0.04500713 -0.04592384  0.06354154\n",
      "  -0.20456355 -0.16977341  0.05491995  0.06512531 -0.16382054 -0.07446838\n",
      "  -0.24735532 -0.11224207  0.00649107  0.03351484 -0.2275344   0.19829651\n",
      "   0.02154289  0.02694849  0.0408656   0.12049888 -0.21950542  0.09120664\n",
      "   0.23137275  0.          0.          0.          0.03722217 -0.19848651\n",
      "   0.06645888 -0.1069375   0.11603587  0.14876587 -0.18825065 -0.27755316\n",
      "  -0.22171622 -0.07279471  0.08435503  0.05994084  0.09867092  0.17826085\n",
      "   0.12784306  0.         -0.15835098  0.08471749  0.1390151  -0.18118351\n",
      "  -0.18957428  0.10857144 -0.0269264  -0.31421941 -0.20848781  0.15472193\n",
      "  -0.24913891 -0.1327112  -0.15626671  0.10488829 -0.04019678 -0.23663404\n",
      "   0.08395397  0.10068037 -0.20067201 -0.16856487  0.04366616  0.05562894\n",
      "   0.13746886 -0.20391959  0.02889751  0.01492451  0.          0.\n",
      "  -0.18800979  0.04255645 -0.02344889  0.11474698  0.1205762   0.\n",
      "   0.          0.         -0.19993754  0.07515605  0.1496224   0.02357379\n",
      "   0.24407804  0.02422573  0.21937546  0.00607829  0.1195047   0.17967054\n",
      "  -0.06525662  0.17653203  0.14619069 -0.24047294  0.14824288  0.\n",
      "   0.13343251  0.04964255 -0.05958709 -0.09697927  0.40804577  0.23350532\n",
      "   0.          0.35553636  0.114914    0.         -0.04335205  0.00934855\n",
      "  -0.03712199  0.21068535 -0.54587122 -0.01621306  0.          0.17116933\n",
      "   0.11663527  0.03794053  0.19685296 -0.15257981 -0.0473519  -0.05110459\n",
      "   0.11563733  0.16545208 -0.10691695 -0.01622095 -0.03003178 -0.16100811\n",
      "   0.14773388 -0.10602693  0.          0.05996586 -0.06267178  0.\n",
      "   0.          0.26094595  0.         -0.05917098]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiang\\anaconda3\\envs\\dsitf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit model\n",
    "logreg.fit(Xs_train, y_train)\n",
    "\n",
    "print(f'Logistic Regression Intercept: {logreg.intercept_}')\n",
    "print(f'Logistic Regression Coefficient: {logreg.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ab9ae47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>year_2013</td>\n",
       "      <td>0.842676</td>\n",
       "      <td>0.842676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>week_32</td>\n",
       "      <td>0.733135</td>\n",
       "      <td>0.733135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>dayofweek_3</td>\n",
       "      <td>-0.647379</td>\n",
       "      <td>0.647379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>week_24</td>\n",
       "      <td>-0.621668</td>\n",
       "      <td>0.621668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>week_33</td>\n",
       "      <td>0.604475</td>\n",
       "      <td>0.604475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>week_26</td>\n",
       "      <td>-0.579849</td>\n",
       "      <td>0.579849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>week_25</td>\n",
       "      <td>-0.563510</td>\n",
       "      <td>0.563510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>codesum_RA BR</td>\n",
       "      <td>-0.545871</td>\n",
       "      <td>0.545871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>week_23</td>\n",
       "      <td>-0.531448</td>\n",
       "      <td>0.531448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>week_31</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>0.531366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>week_35</td>\n",
       "      <td>0.515922</td>\n",
       "      <td>0.515922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>week_38</td>\n",
       "      <td>0.501662</td>\n",
       "      <td>0.501662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>week_37</td>\n",
       "      <td>0.498548</td>\n",
       "      <td>0.498548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>week_34</td>\n",
       "      <td>0.479176</td>\n",
       "      <td>0.479176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>week_29</td>\n",
       "      <td>-0.476367</td>\n",
       "      <td>0.476367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>species_CULEX RESTUANS</td>\n",
       "      <td>-0.456137</td>\n",
       "      <td>0.456137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>year_2011</td>\n",
       "      <td>-0.443455</td>\n",
       "      <td>0.443455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>trap_T900</td>\n",
       "      <td>0.408046</td>\n",
       "      <td>0.408046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>year_2009</td>\n",
       "      <td>-0.398335</td>\n",
       "      <td>0.398335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>week_36</td>\n",
       "      <td>0.391779</td>\n",
       "      <td>0.391779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   variable      coef  abs_coef\n",
       "27                year_2013  0.842676  0.842676\n",
       "38                  week_32  0.733135  0.733135\n",
       "50              dayofweek_3 -0.647379  0.647379\n",
       "30                  week_24 -0.621668  0.621668\n",
       "39                  week_33  0.604475  0.604475\n",
       "32                  week_26 -0.579849  0.579849\n",
       "31                  week_25 -0.563510  0.563510\n",
       "212           codesum_RA BR -0.545871  0.545871\n",
       "29                  week_23 -0.531448  0.531448\n",
       "37                  week_31  0.531366  0.531366\n",
       "41                  week_35  0.515922  0.515922\n",
       "44                  week_38  0.501662  0.501662\n",
       "43                  week_37  0.498548  0.498548\n",
       "40                  week_34  0.479176  0.479176\n",
       "35                  week_29 -0.476367  0.476367\n",
       "53   species_CULEX RESTUANS -0.456137  0.456137\n",
       "25                year_2011 -0.443455  0.443455\n",
       "202               trap_T900  0.408046  0.408046\n",
       "23                year_2009 -0.398335  0.398335\n",
       "42                  week_36  0.391779  0.391779"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display Coefficients\n",
    "coefs = pd.DataFrame({'variable':X.columns,\n",
    "                            'coef':logreg.coef_[0],\n",
    "                            'abs_coef':np.abs(logreg.coef_[0])\n",
    "                     })\n",
    "\n",
    "coefs.sort_values('abs_coef', inplace=True, ascending=False)\n",
    "coefs.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4c910614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9458895311496468, 0.9436416184971098)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(Xs_train, y_train), logreg.score(Xs_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8740b39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression summary of accuracy scores:\n",
      "\n",
      "Using GridSearchCV best params suggested,\n",
      "Training corpus accuracy = 0.945\n",
      "Testing corpus accuracy = 0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiang\\anaconda3\\envs\\dsitf\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n",
      "C:\\Users\\xiang\\anaconda3\\envs\\dsitf\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "# Summary scores of CountVectorizer and LogisticRegression.\n",
    "print(\"LogisticRegression summary of accuracy scores:\")\n",
    "#print(f\"GridSearchCV best accuracy = {round(gs_pipe.best_score_, 3)}\")\n",
    "print(\"\\nUsing GridSearchCV best params suggested,\")\n",
    "print(f\"Training corpus accuracy = {round(logreg.score(X_train, y_train), 3)}\")\n",
    "print(f\"Testing corpus accuracy = {round(logreg.score(X_holdout, y_holdout), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5582a350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb9e391f",
   "metadata": {},
   "source": [
    "### Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8569ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6a61e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88d4735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e1efe1d",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76f9da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d787ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bcf709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "922fc869",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c8c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab1414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3343f55c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c20b0a4",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dd7dcb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9446050096339114"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(\n",
    "    n_estimators = 100,\n",
    "    learning_rate = 0.9\n",
    "    # in general, if n_estimators is high, then learning_rate should be low\n",
    "    # but we can use GridSearchCV\n",
    ")\n",
    "ada.fit(X_train, y_train)\n",
    "ada.score(X_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0eaedca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9446050096339114"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
    "ada_params = {\n",
    "    'n_estimators': [50,100, 150],\n",
    "    'base_estimator__max_depth': [1,2],\n",
    "    'learning_rate': [.8, .9, 1.]\n",
    "    # you can also tune by all hyperparameters of DecisionTree\n",
    "}\n",
    "gs = GridSearchCV(\n",
    "    ada, \n",
    "    param_grid=ada_params, \n",
    "    cv=5\n",
    ")\n",
    "gs.fit(X_train, y_train)\n",
    "gs.score(X_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a609211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa1f78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b46b4c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9089595375722543"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(\n",
    "    n_estimators = 100,\n",
    "    learning_rate = 0.9\n",
    "    # in general, if n_estimators is high, then learning_rate should be low\n",
    "    # but we can use GridSearchCV\n",
    ")\n",
    "ada.fit(Xsm_train, ysm_train)\n",
    "ada.score(Xs_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "efaf83be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9272639691714836"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
    "ada_params = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'base_estimator__max_depth': [1,2],\n",
    "    'learning_rate': [.8, .9, 1.]\n",
    "    # you can also tune by all hyperparameters of DecisionTree\n",
    "}\n",
    "gs = GridSearchCV(\n",
    "    ada, \n",
    "    param_grid=ada_params, \n",
    "    cv=5\n",
    ")\n",
    "gs.fit(Xsm_train, ysm_train)\n",
    "gs.score(Xs_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6dfdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_metrics(gs, X_train, y_train, X_test, y_test, modelname):\n",
    "    '''Generates confusion matrix and adds scores to summary_df'''\n",
    "    \n",
    "    #Generate confusion matrix\n",
    "    y_pred = gs.predict(X_test)\n",
    "    confusion_matrix(y_test, # True values.\n",
    "                     y_pred)  # Predicted values.\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel();\n",
    "\n",
    "    # Adding the scores into summary_df\n",
    "    \n",
    "    summary_df.loc[1] = [\n",
    "        modelname,\n",
    "        #'CountVec/LogisticRegression',\n",
    "        round(gs.best_score_, 3),\n",
    "        round(gs.score(X_train, y_train),3),\n",
    "        round(gs.score(X_test, y_test),3),\n",
    "        round(metrics.accuracy_score(y_test, y_pred),3),\n",
    "        round(metrics.recall_score(y_test, y_pred),3),\n",
    "        round(tn/(tn+fp),3),\n",
    "        round(metrics.f1_score(y_test, y_pred),3),\n",
    "        str(gs.best_params_),\n",
    "    ]\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    plot_confusion_matrix(gs, X_test, y_test, cmap='Blues', \n",
    "                          display_labels=['WNV Present', 'WNV Not Present'],\n",
    "                          normalize='true');  \n",
    "    plt.title(label=modelname, fontsize=14)\n",
    "    plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bab2c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame(columns=[\n",
    "    'transformer_estimator', \n",
    "    'best_score', \n",
    "    'train_score',\n",
    "    'holdout_score',\n",
    "    'accuracy', \n",
    "    'sensitivity',\n",
    "    'specificity',\n",
    "    'f1_score',\n",
    "    'best_params', \n",
    "])\n",
    "summary_df.loc[1] = [\n",
    "    modelname,\n",
    "    #'CountVec/LogisticRegression',\n",
    "    round(gs.best_score_, 3),\n",
    "    round(gs.score(X_train, y_train),3),\n",
    "    round(gs.score(X_test, y_test),3),\n",
    "    round(metrics.accuracy_score(y_test, y_pred),3),\n",
    "    round(metrics.recall_score(y_test, y_pred),3),\n",
    "    round(tn/(tn+fp),3),\n",
    "    round(metrics.f1_score(y_test, y_pred),3),\n",
    "    str(gs.best_params_),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c65dd386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11770, 238)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xsm_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "031c15ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'recall_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_980\\1628347090.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXsm_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mysm_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXs_holdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_holdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ADA Boost Classifier'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_980\\2185395355.py\u001b[0m in \u001b[0;36mmodel_metrics\u001b[1;34m(gs, X_train, y_train, X_test, y_test, modelname)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtn\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'recall_score'"
     ]
    }
   ],
   "source": [
    "model_metrics(gs, Xsm_train, ysm_train, Xs_holdout, y_holdout, 'ADA Boost Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30410c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a96584",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(gs.best_estimator_.feature_importances_).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9779eb",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd856eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = GradientBoostingClassifier()\n",
    "gboost_params = {\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'n_estimators': [100, 125, 150],\n",
    "    'learning_rate': [.08, .1, .12]\n",
    "}\n",
    "gb_gs = GridSearchCV(\n",
    "    gboost, \n",
    "    param_grid=gboost_params, \n",
    "    cv=3\n",
    ")\n",
    "gb_gs.fit(Xsm_train, ysm_train)\n",
    "gb_gs.score(Xs_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a3a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gb_gs.best_score_)\n",
    "gb_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cfe9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics(gb_gs, X_train, y_train, X_holdout, y_holdout, 'Gradient Boosting Classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e920531",
   "metadata": {},
   "source": [
    "### Neutro Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3debad69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9073342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e7798d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb68f689",
   "metadata": {},
   "source": [
    "### AUC-ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a5563ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cvec_lr_gs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_980\\3278258354.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_roc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcvec_lr_gs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'LogisticRegression-CVEC(GS)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lightgrey'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplot_roc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcvec_nb_gs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'MultinomialNB-CVEC(GS)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lightgrey'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplot_roc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtvec_svc_gs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SupportVectorClassifier-TVEC(GS)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lightgrey'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplot_roc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtvec_lr_gs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'LogisticRegression-TVEC(GS)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'blue'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cvec_lr_gs' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAssAAAJDCAYAAAD961luAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVBElEQVR4nO3dX4ild33H8c+3uwb8VyNmKzZ/MJRoTMEUHaMXirHSmuSioWAhUZQGYQk14qW50gtv6oUgYnRZJARvzEUNGks09EYtxNBsQKMxRJaEJtsISVQsKDRs8u3FjGU6nm/mZHLmzLp5vWBhn+f85swX5sfum2efPU91dwAAgD/0Jwc9AAAAnKnEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMdo3lqrq1qp6sqp8Or1dVfbGqTlbVA1X1ttWPCQAA67fMleXbklz1PK9fneSSrV9Hk3zlxY8FAAAHb9dY7u4fJPnV8yy5NsnXetO9Sc6tqjesakAAADgoq7hn+fwkj287PrV1DgAA/qgdXsF71IJzC5+hXVVHs3mrRl75yle+/dJLL13BtwcAgNn999//dHcf2cvXriKWTyW5cNvxBUmeWLSwu48nOZ4kGxsbfeLEiRV8ewAAmFXVf+71a1dxG8adST669akY70rym+7+xQreFwAADtSuV5ar6utJrkxyXlWdSvKZJC9Lku4+luSuJNckOZnkd0lu2K9hAQBgnXaN5e6+fpfXO8nHVzYRAACcITzBDwAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABkvFclVdVVUPV9XJqrp5weuvqapvV9WPq+rBqrph9aMCAMB67RrLVXUoyS1Jrk5yWZLrq+qyHcs+nuRn3X15kiuTfL6qzlnxrAAAsFbLXFm+IsnJ7n6ku59JcnuSa3es6SSvrqpK8qokv0pyeqWTAgDAmi0Ty+cneXzb8amtc9t9KclbkjyR5CdJPtndz61kQgAAOCDLxHItONc7jj+Q5EdJ/jzJXyX5UlX96R+8UdXRqjpRVSeeeuqpFzgqAACs1zKxfCrJhduOL8jmFeTtbkhyR286meTRJJfufKPuPt7dG929ceTIkb3ODAAAa7FMLN+X5JKqunjrP+1dl+TOHWseS/L+JKmq1yd5c5JHVjkoAACs2+HdFnT36aq6KcndSQ4lubW7H6yqG7deP5bks0luq6qfZPO2jU9199P7ODcAAOy7XWM5Sbr7riR37Th3bNvvn0jyt6sdDQAADpYn+AEAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwEAsAwDAQCwDAMBALAMAwGCpWK6qq6rq4ao6WVU3D2uurKofVdWDVfX91Y4JAADrd3i3BVV1KMktSf4myakk91XVnd39s21rzk3y5SRXdfdjVfVn+zQvAACszTJXlq9IcrK7H+nuZ5LcnuTaHWs+lOSO7n4sSbr7ydWOCQAA67dMLJ+f5PFtx6e2zm33piSvrarvVdX9VfXRVQ0IAAAHZdfbMJLUgnO94H3enuT9SV6e5IdVdW93//z/vVHV0SRHk+Siiy564dMCAMAaLXNl+VSSC7cdX5DkiQVrvtvdv+3up5P8IMnlO9+ou49390Z3bxw5cmSvMwMAwFosE8v3Jbmkqi6uqnOSXJfkzh1rvpXkPVV1uKpekeSdSR5a7agAALBeu96G0d2nq+qmJHcnOZTk1u5+sKpu3Hr9WHc/VFXfTfJAkueSfLW7f7qfgwMAwH6r7p23H6/HxsZGnzhx4kC+NwAALx1VdX93b+zlaz3BDwAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZLxXJVXVVVD1fVyaq6+XnWvaOqnq2qD65uRAAAOBi7xnJVHUpyS5Krk1yW5PqqumxY97kkd696SAAAOAjLXFm+IsnJ7n6ku59JcnuSaxes+0SSbyR5coXzAQDAgVkmls9P8vi241Nb5/5PVZ2f5O+THFvdaAAAcLCWieVacK53HH8hyae6+9nnfaOqo1V1oqpOPPXUU0uOCAAAB+PwEmtOJblw2/EFSZ7YsWYjye1VlSTnJbmmqk539ze3L+ru40mOJ8nGxsbO4AYAgDPKMrF8X5JLquriJP+V5LokH9q+oLsv/v3vq+q2JP+6M5QBAOCPza6x3N2nq+qmbH7KxaEkt3b3g1V149br7lMGAOCstMyV5XT3XUnu2nFuYSR39z+++LEAAODgeYIfAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMlorlqrqqqh6uqpNVdfOC1z9cVQ9s/bqnqi5f/agAALBeu8ZyVR1KckuSq5NcluT6qrpsx7JHk7y3u9+a5LNJjq96UAAAWLdlrixfkeRkdz/S3c8kuT3JtdsXdPc93f3rrcN7k1yw2jEBAGD9lonl85M8vu341Na5yceSfOfFDAUAAGeCw0usqQXneuHCqvdlM5bfPbx+NMnRJLnooouWHBEAAA7GMleWTyW5cNvxBUme2Lmoqt6a5KtJru3uXy56o+4+3t0b3b1x5MiRvcwLAABrs0ws35fkkqq6uKrOSXJdkju3L6iqi5LckeQj3f3z1Y8JAADrt+ttGN19uqpuSnJ3kkNJbu3uB6vqxq3XjyX5dJLXJflyVSXJ6e7e2L+xAQBg/1X3wtuP993GxkafOHHiQL43AAAvHVV1/14v5HqCHwAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADMQyAAAMxDIAAAzEMgAADJaK5aq6qqoerqqTVXXzgterqr649foDVfW21Y8KAADrtWssV9WhJLckuTrJZUmur6rLdiy7OsklW7+OJvnKiucEAIC1W+bK8hVJTnb3I939TJLbk1y7Y821Sb7Wm+5Ncm5VvWHFswIAwFotE8vnJ3l82/GprXMvdA0AAPxRObzEmlpwrvewJlV1NJu3aSTJ/1TVT5f4/ry0nJfk6YMegjOOfcEi9gWL2Bcs8ua9fuEysXwqyYXbji9I8sQe1qS7jyc5niRVdaK7N17QtJz17AsWsS9YxL5gEfuCRarqxF6/dpnbMO5LcklVXVxV5yS5LsmdO9bcmeSjW5+K8a4kv+nuX+x1KAAAOBPsemW5u09X1U1J7k5yKMmt3f1gVd249fqxJHcluSbJySS/S3LD/o0MAADrscxtGOnuu7IZxNvPHdv2+07y8Rf4vY+/wPW8NNgXLGJfsIh9wSL2BYvseV/UZucCAAA7edw1AAAM9j2WPSqbRZbYFx/e2g8PVNU9VXX5QczJeu22L7ate0dVPVtVH1znfByMZfZFVV1ZVT+qqger6vvrnpH1W+LvkddU1ber6sdb+8L/pzrLVdWtVfXk9NHEe23OfY1lj8pmkSX3xaNJ3tvdb03y2bgH7ay35L74/brPZfM/HXOWW2ZfVNW5Sb6c5O+6+y+T/MO652S9lvzz4uNJftbdlye5Msnntz7Vi7PXbUmuep7X99Sc+31l2aOyWWTXfdHd93T3r7cO783mZ3dzdlvmz4sk+USSbyR5cp3DcWCW2RcfSnJHdz+WJN1tb5z9ltkXneTVVVVJXpXkV0lOr3dM1qm7f5DNn/NkT82537HsUdks8kJ/5h9L8p19nYgzwa77oqrOT/L3SY6Fl4pl/rx4U5LXVtX3qur+qvro2qbjoCyzL76U5C3ZfEjaT5J8srufW894nKH21JxLfXTci7CyR2VzVln6Z15V78tmLL97XyfiTLDMvvhCkk9197ObF4t4CVhmXxxO8vYk70/y8iQ/rKp7u/vn+z0cB2aZffGBJD9K8tdJ/iLJv1XVv3f3f+/zbJy59tSc+x3LK3tUNmeVpX7mVfXWJF9NcnV3/3JNs3FwltkXG0lu3wrl85JcU1Wnu/uba5mQg7Ds3yNPd/dvk/y2qn6Q5PIkYvnstcy+uCHJP289C+JkVT2a5NIk/7GeETkD7ak59/s2DI/KZpFd90VVXZTkjiQfcXXoJWPXfdHdF3f3G7v7jUn+Jck/CeWz3jJ/j3wryXuq6nBVvSLJO5M8tOY5Wa9l9sVj2fzXhlTV65O8Ockja52SM82emnNfryx7VDaLLLkvPp3kdUm+vHUV8XR3bxzUzOy/JfcFLzHL7IvufqiqvpvkgSTPJflqdy/86CjODkv+efHZJLdV1U+y+c/vn+rupw9saPZdVX09m598cl5VnUrymSQvS15cc3qCHwAADDzBDwAABmIZAAAGYhkAAAZiGQAABmIZAAAGYhkAAAZiGQAABmIZAAAG/wvxicdhMCk7owAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12,10))\n",
    "plot_roc_curve(cvec_lr_gs, X_test, y_test, ax=ax, name='LogisticRegression-CVEC(GS)', color='lightgrey')\n",
    "plot_roc_curve(cvec_nb_gs, X_test, y_test, ax=ax, name='MultinomialNB-CVEC(GS)', color='lightgrey')\n",
    "plot_roc_curve(tvec_svc_gs, X_test, y_test, ax=ax, name='SupportVectorClassifier-TVEC(GS)', color='lightgrey')\n",
    "plot_roc_curve(tvec_lr_gs, X_test, y_test, ax=ax, name='LogisticRegression-TVEC(GS)', color='blue')\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--', label='Random Guess')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e282f9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
